# ASV Dataset Preparation System

A comprehensive, production-ready system for analyzing, preparing, and converting ASVspoof-2019 dataset for compatibility with Deep ASV Detection framework.

## Overview

This system provides a complete solution for ASVspoof-2019 dataset preparation with **Task 1-5 Integration**, featuring professional CLI interface, reset functionality, and comprehensive dataset conversion capabilities.

## ğŸš€ Key Features

### ğŸ”„ Project Management
- **Reset Functionality**: Complete project cleanup and fresh start capability
- **Status Monitoring**: Real-time project status and disk usage tracking
- **Backup & Recovery**: Automatic backup creation and rollback mechanisms
- **Professional CLI**: Intuitive command-line interface with multiple presets

### ğŸ” Comprehensive Dataset Analysis
- **File Inventory**: Complete analysis of 122,299 audio files (7.11 GB)
- **Protocol Analysis**: Parsing and validation of ASVspoof-2019 protocol files
- **Speaker Distribution**: Analysis of 107 unique speakers
- **Attack Type Mapping**: Categorization of 19 spoofing attack types (A01-A19)
- **User Mapping Strategy**: Intelligent mapping to Deep ASV Detection format

### ğŸ“Š Dataset Conversion & Splitting
- **Multiple Splitting Options**: 3 different dataset splitting strategies
- **File Organization**: Automated file renaming and directory structure creation
- **Label Mapping**: bonafide â†’ genuine, spoof â†’ deepfake conversion
- **Attack Categorization**: TTS, VC, and TTS_VC classification

### ğŸ—ï¸ Professional Architecture
- **Modular Design**: Clean separation of concerns with reusable components
- **Configuration Management**: 11 predefined presets for different use cases
- **Robust Error Handling**: Comprehensive validation and recovery mechanisms
- **Virtual Environment**: Isolated Python environment with managed dependencies

## ğŸ“ Project Structure

```
asv_dataset_preparation/
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ asv_cli.py                     # Main CLI interface
â”‚   â”œâ”€â”€ asv_dataset_integration.py     # Core integration system
â”‚   â”œâ”€â”€ data_structure_analyzer.py     # Dataset analysis
â”‚   â”œâ”€â”€ file_organization_system.py    # File mapping and organization
â”‚   â”œâ”€â”€ dataset_splitting_balancing.py # Dataset splitting strategies
â”‚   â””â”€â”€ test_integration_system.py     # Comprehensive test suite
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ dataset_config.py              # Dataset configuration
â”‚   â””â”€â”€ integration_configs.py         # Integration presets
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ protocol_parser.py             # Protocol file parsing
â”‚   â””â”€â”€ logging_utils.py               # Professional logging
â”œâ”€â”€ output/
â”‚   â”œâ”€â”€ analysis/                      # Analysis results
â”‚   â”œâ”€â”€ converted_data/                # Converted dataset output
â”‚   â””â”€â”€ integration_*/                 # Integration run outputs
â”œâ”€â”€ logs/                              # Comprehensive logging
â”œâ”€â”€ docs/                              # Documentation
â”œâ”€â”€ venv/                              # Virtual environment
â””â”€â”€ requirements.txt                   # Dependencies
```

## ğŸ› ï¸ Installation & Setup

### 1. Environment Setup
```bash
cd "ASV Datasets/asv_dataset_preparation"
python3 -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
pip install --upgrade pip
pip install -r requirements.txt
```

### 2. Environment Validation
```bash
# Validate system setup
python scripts/asv_cli.py validate
```

## ğŸ¯ Quick Start

### CLI Interface
```bash
# Activate virtual environment
source venv/bin/activate

# Show available presets
python scripts/asv_cli.py list-presets

# Show project status
python scripts/asv_cli.py status

# Run quick analysis
python scripts/asv_cli.py run --preset quick_analysis --yes

# Reset project for fresh start
python scripts/asv_cli.py reset
```

### Available Presets

#### ğŸ“‚ Analysis & Testing
- **`quick_analysis`**: Fast dataset exploration (< 1 second)
- **`development_testing`**: Development with subset processing

#### ğŸ“‚ Production Configurations
- **`production_conservative`**: Safe production with comprehensive validation
- **`production_balanced`**: Balanced production with data redistribution
- **`production_fast`**: Fast production with minimal validation

#### ğŸ“‚ Research Configurations
- **`research_comprehensive`**: Detailed analysis for research purposes

#### ğŸ“‚ Splitting Only
- **`splitting_only_option_a`**: Original splits (train/dev/eval)
- **`splitting_only_option_b`**: Combined redistribution (70/15/15)
- **`splitting_only_option_c`**: Train+Dev vs Eval

#### ğŸ“‚ Custom Configurations
- **`custom_balanced_small`**: Small balanced dataset
- **`custom_imbalanced_large`**: Large imbalanced dataset

## ğŸ“Š Dataset Analysis Results

### Key Metrics
- **Total Files**: 122,299 audio files (7.11 GB)
- **Speakers**: 107 unique speakers â†’ 106 user directories
- **Attack Types**: 19 different spoofing systems
- **Label Distribution**: 10.3% genuine, 89.7% spoofed
- **Conversion Efficiency**: 99.9% file mapping success

### Attack Type Categories
- **TTS (Text-to-Speech)**: A01, A02, A03, A04, A07, A08, A09, A10, A11, A12, A16
- **VC (Voice Conversion)**: A05, A06, A17, A18, A19
- **TTS_VC (Hybrid)**: A13, A14, A15

### Dataset Splitting Options

#### Option A: Original Splits
- **TRAIN**: 25,380 files (20 users)
- **DEV**: 24,844 files (19 users)
- **TEST**: 71,237 files (67 users)

#### Option B: Balanced Redistribution (70/15/15)
- **TRAIN**: 84,945 files (106 users)
- **DEV**: 18,125 files (106 users)
- **TEST**: 18,391 files (106 users)

#### Option C: Train+Dev vs Eval
- **TRAIN**: 50,224 files (39 users)
- **TEST**: 71,237 files (67 users)

## ğŸ”„ Project Management

### Reset Functionality
```bash
# Show current project status
python scripts/asv_cli.py status

# Reset project (with confirmation)
python scripts/asv_cli.py reset

# Force reset (skip confirmation)
python scripts/asv_cli.py reset --force
```

### Status Monitoring
The system provides real-time monitoring of:
- Total files and disk usage
- Directory status (output, logs, analysis, converted_data)
- Last run timestamp
- Cleanup recommendations

## ğŸ”§ Advanced Usage

### Custom Configuration
```bash
# Show specific preset details
python scripts/asv_cli.py show-preset production_balanced

# Run with custom parameters
python scripts/asv_cli.py run --preset production_balanced --dry-run

# Create preset configuration files
python scripts/asv_cli.py create-configs
```

### Integration Testing
```bash
# Run comprehensive system tests
python scripts/test_integration_system.py
```

## ğŸ“ File Format Conversion

### ASVspoof-2019 â†’ Deep ASV Detection

**Original Format:**
```
LA_T_1234567.flac  # Training file from speaker LA_0001, attack A07
```

**Converted Format:**
```
data/user_01/user01_genuine_001.flac      # Genuine audio
data/user_01/user01_deepfake_tts_001.flac # TTS spoofed audio
data/user_01/user01_deepfake_vc_001.flac  # VC spoofed audio
```

### Directory Structure
```
converted_data/
â”œâ”€â”€ train/
â”‚   â”œâ”€â”€ user_01/
â”‚   â”‚   â”œâ”€â”€ user01_genuine_001.flac
â”‚   â”‚   â”œâ”€â”€ user01_genuine_002.flac
â”‚   â”‚   â”œâ”€â”€ user01_deepfake_tts_001.flac
â”‚   â”‚   â””â”€â”€ user01_deepfake_vc_001.flac
â”‚   â””â”€â”€ user_02/
â”‚       â””â”€â”€ ...
â”œâ”€â”€ dev/
â””â”€â”€ test/
```

## âœ… Task Completion Status

### âœ… Task 1: Data Structure Analysis (COMPLETED)
- Comprehensive dataset analysis of 122,299 files
- File counting and size analysis across all splits
- Professional reporting with JSON/CSV outputs

### âœ… Task 2: File Label Mapping (COMPLETED)
- Protocol file parsing with validation
- 121,461 file-to-label mappings created
- Attack type categorization and labeling

### âœ… Task 3: Speaker Assignment (COMPLETED)
- Speaker-to-user mapping algorithm
- 107 speakers â†’ 106 user directories
- Balanced file distribution

### âœ… Task 4: Dataset Splitting (COMPLETED)
- Three splitting strategies implemented
- Comprehensive testing and validation
- Flexible configuration options

### âœ… Task 5: Integration System (COMPLETED)
- Complete CLI interface with 11 presets
- Reset and status monitoring functionality
- Production-ready integration pipeline
- Comprehensive error handling and recovery

## ğŸ” Quality Assurance

### Testing Coverage
- **Environment Validation**: System setup verification
- **Configuration Testing**: All 11 presets validated
- **Integration Testing**: End-to-end pipeline testing
- **Error Handling**: Recovery and rollback testing
- **Performance Testing**: Quick analysis (< 1 second)

### Professional Standards
- **Type Hints**: Full type annotation throughout
- **Documentation**: Comprehensive docstrings and comments
- **Error Handling**: Robust exception handling and validation
- **Logging**: Professional logging with timestamps and levels
- **Modularity**: Clean architecture with separation of concerns

## ğŸ“‹ Dependencies

```txt
pandas>=1.5.0          # Data analysis and manipulation
numpy>=1.24.0          # Numerical computations
matplotlib>=3.6.0      # Data visualization
seaborn>=0.12.0        # Statistical visualization
tqdm>=4.64.0           # Progress bars
jsonschema>=4.17.0     # JSON validation
```

## ğŸš¨ Troubleshooting

### Common Issues
1. **Dataset Path Issues**: Run `python scripts/asv_cli.py validate`
2. **Permission Errors**: Check file permissions in output directories
3. **Memory Issues**: Use `quick_analysis` preset for large datasets
4. **Disk Space**: Use `python scripts/asv_cli.py status` to monitor usage

### Recovery
```bash
# Reset and start fresh
python scripts/asv_cli.py reset --force

# Validate environment
python scripts/asv_cli.py validate

# Run basic analysis
python scripts/asv_cli.py run --preset quick_analysis --yes
```

## ğŸ“ Support

For issues or questions:
1. Check the comprehensive logging in `logs/` directory
2. Use `python scripts/asv_cli.py validate` for environment issues
3. Review the integration reports in `output/integration_*/reports/`

---

**Author**: ASV Dataset Preparation System  
**Version**: 2.0.0  
**Last Updated**: June 2025  
**Status**: Production Ready âœ… 